{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# koki2 \u2014 Stage 2 modulator grid (L1.0 deplete/respawn + L1.1 intermittent gradient)\n",
        "\n",
        "This notebook runs a **Stage 2** comparison to test whether consequence-aligned neuromodulation (drive/event) can yield useful within-life plasticity without the hazard-contact regression observed with spike-modulated plasticity.\n",
        "\n",
        "Protocol (aligned with `PLAN.md`/`WORK.md`):\n",
        "- Environment: L1.0 **deplete/respawn** + L0.2 **harmful sources** + L1.1 **intermittent gradient** (`--grad-dropout-p 0.5`).\n",
        "- Stronger effect size: `--steps 256`, hazard persistence pressure `--bad-source-respawn-delay 0`.\n",
        "- Grid: no-plastic vs plastic with `--modulator-kind {spike,drive,event}` and `--plast-eta \u2208 {0.01, 0.05}` (`--plast-lambda 0.9`).\n",
        "\n",
        "Repo hygiene tip: if you opened this from GitHub, use **File \u2192 Save a copy in Drive** (instead of saving back to GitHub) to avoid committing execution outputs/metadata.\n",
        "\n",
        "1. **Runtime \u2192 Change runtime type** \u2192 select **GPU** (L4/T4/A100, etc.) or **TPU** (v5/v6e, etc.).\n",
        "2. Run the cells top-to-bottom.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Mount Google Drive\n",
        "\n",
        "If you want `runs/` to persist across sessions, mount Drive and set `OUT_ROOT` to a Drive path (later).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clone the repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REPO_URL = \"https://github.com/Krisztiaan/koki2.git\"  # override if using a fork\n",
        "REPO_DIR = \"koki2\"\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import subprocess\n",
        "\n",
        "\n",
        "def _run(cmd: list[str]) -> None:\n",
        "    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    if proc.returncode != 0:\n",
        "        print(proc.stdout)\n",
        "        proc.check_returncode()\n",
        "\n",
        "\n",
        "repo_path = pathlib.Path(REPO_DIR)\n",
        "if not repo_path.exists():\n",
        "    _run([\"git\", \"clone\", \"--depth\", \"1\", \"--quiet\", REPO_URL, REPO_DIR])\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"Working dir:\", pathlib.Path.cwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install JAX for your accelerator\n",
        "\n",
        "This picks **TPU** if a TPU runtime is detected, otherwise picks **GPU** if `nvidia-smi` is available, else falls back to **CPU**.\n",
        "\n",
        "If you manually change the runtime accelerator type after this, re-run this cell and restart the runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "os.environ.setdefault(\"PIP_DISABLE_PIP_VERSION_CHECK\", \"1\")\n",
        "\n",
        "\n",
        "def _run(cmd: list[str], *, check: bool = True) -> None:\n",
        "    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    if check and proc.returncode != 0:\n",
        "        print(proc.stdout)\n",
        "        proc.check_returncode()\n",
        "\n",
        "\n",
        "def _pip(*args: str) -> None:\n",
        "    _run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-U\", *args], check=True)\n",
        "\n",
        "\n",
        "def _pip_uninstall(*args: str) -> None:\n",
        "    _run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-q\", \"-y\", *args], check=False)\n",
        "\n",
        "\n",
        "def _is_tpu_runtime() -> bool:\n",
        "    return any(k in os.environ for k in [\"COLAB_TPU_ADDR\", \"TPU_NAME\", \"XRT_TPU_CONFIG\"])\n",
        "\n",
        "\n",
        "def _has_nvidia_smi() -> bool:\n",
        "    return subprocess.run([\"bash\", \"-lc\", \"command -v nvidia-smi\"], check=False).returncode == 0\n",
        "\n",
        "\n",
        "accelerator = \"tpu\" if _is_tpu_runtime() else (\"gpu\" if _has_nvidia_smi() else \"cpu\")\n",
        "print(\"Detected accelerator:\", accelerator)\n",
        "\n",
        "# Colab-friendly default: avoid preallocating most GPU memory up-front.\n",
        "if accelerator == \"gpu\":\n",
        "    os.environ.setdefault(\"XLA_PYTHON_CLIENT_PREALLOCATE\", \"false\")\n",
        "\n",
        "# Keep the environment clean if you rerun this cell after switching runtime type.\n",
        "_pip_uninstall(\"jax\", \"jaxlib\")\n",
        "\n",
        "_pip(\"pip\")\n",
        "\n",
        "# JAX wheels/indices (adjust if Colab images change).\n",
        "JAX_CPU_PKG = \"jax\"\n",
        "JAX_GPU_PKG = \"jax[cuda12_pip]\"  # if this fails, try: jax[cuda11_pip]\"\n",
        "JAX_GPU_WHL_INDEX = \"https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\"\n",
        "JAX_TPU_PKG = \"jax[tpu]\"\n",
        "JAX_TPU_WHL_INDEX = \"https://storage.googleapis.com/jax-releases/libtpu_releases.html\"\n",
        "\n",
        "if accelerator == \"tpu\":\n",
        "    _pip(JAX_TPU_PKG, \"-f\", JAX_TPU_WHL_INDEX)\n",
        "elif accelerator == \"gpu\":\n",
        "    _pip(JAX_GPU_PKG, \"-f\", JAX_GPU_WHL_INDEX)\n",
        "else:\n",
        "    _pip(JAX_CPU_PKG)\n",
        "\n",
        "print(\"JAX install finished.\")\n",
        "print(\"If you see import/backend issues below, use Runtime \u2192 Restart runtime, then rerun from the top.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install koki2 (editable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "proc = subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\", \"--no-deps\"],\n",
        "    text=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        ")\n",
        "if proc.returncode != 0:\n",
        "    print(proc.stdout)\n",
        "proc.check_returncode()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check: JAX sees the accelerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax\n",
        "\n",
        "print(\"jax:\", jax.__version__)\n",
        "print(\"backend:\", jax.default_backend())\n",
        "print(\"devices:\")\n",
        "for d in jax.devices():\n",
        "    print(\" -\", d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run: Stage 2 hazard persistence + eta=0 controls (ES + held-out eval)\n",
        "\n",
        "This runs training for each condition, then evaluates each saved `best_genome.npz` on held-out episodes and writes a JSONL summary under `runs/stage2_scans/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import subprocess\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from statistics import mean, stdev\n",
        "\n",
        "OUT_ROOT = \"runs/stage2_hazp_l10l11\"  # or e.g. \"/content/drive/MyDrive/koki2_runs/stage2_hazp_l10l11\"\n",
        "SEEDS = \"0,1,2,3,4\"\n",
        "\n",
        "GENERATIONS = 30\n",
        "POP_SIZE = 64\n",
        "TRAIN_EPISODES = 4\n",
        "STEPS = 256\n",
        "LOG_EVERY = 10\n",
        "\n",
        "EVAL_EP = 512\n",
        "EVAL_SEEDS = [424242, 0]\n",
        "\n",
        "# Env: L1.0 deplete/respawn + harmful sources + intermittent gradient.\n",
        "# This notebook focuses on **hazard persistence** via bad_source_deplete_p < 1.0, which should increase the value of within-episode consequence learning.\n",
        "ENV_BASE = [\n",
        "    '--deplete-sources',\n",
        "    '--respawn-delay', '4',\n",
        "    '--bad-source-respawn-delay', '0',\n",
        "    '--bad-source-deplete-p', '0.25',\n",
        "    '--num-sources', '4',\n",
        "    '--num-bad-sources', '2',\n",
        "    '--bad-source-integrity-loss', '0.25',\n",
        "    '--grad-dropout-p', '0.5',\n",
        "    '--success-bonus', '50',\n",
        "]\n",
        "\n",
        "PLAST_LAMBDA = 0.9\n",
        "ETA_GRID = [0.01, 0.05]\n",
        "\n",
        "CONDITIONS = [\n",
        "    ('A0', 'noplast', None, []),\n",
        "]\n",
        "for eta in ETA_GRID:\n",
        "    CONDITIONS += [\n",
        "        ('A1', 'spike', eta, ['--plast-enabled', '--plast-eta', str(eta), '--plast-lambda', str(PLAST_LAMBDA), '--modulator-kind', 'spike']),\n",
        "        ('A2', 'drive', eta, ['--plast-enabled', '--plast-eta', str(eta), '--plast-lambda', str(PLAST_LAMBDA), '--modulator-kind', 'drive', '--mod-drive-scale', '1.0']),\n",
        "        ('A3', 'event', eta, ['--plast-enabled', '--plast-eta', str(eta), '--plast-lambda', str(PLAST_LAMBDA), '--modulator-kind', 'event']),\n",
        "    ]\n",
        "\n",
        "pat_out_dir = re.compile(r'out_dir=(\\S+)')\n",
        "pat_seed = re.compile(r'_seed(\\d+)$')\n",
        "pat_kv = re.compile(r'(\\w+)=([-+0-9.eE]+)')\n",
        "\n",
        "def _run(cmd: list[str]) -> str:\n",
        "    proc = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "    if proc.returncode != 0:\n",
        "        print(proc.stdout)\n",
        "    proc.check_returncode()\n",
        "    return proc.stdout\n",
        "\n",
        "stamp = time.strftime('%Y-%m-%d_%H%M%S', time.gmtime())\n",
        "log_path = Path('runs/stage2_scans') / f'{stamp}_stage2_hazp_steps{STEPS}_g{GENERATIONS}_p{POP_SIZE}_ep{TRAIN_EPISODES}_eval{EVAL_EP}.txt'\n",
        "jsonl_path = Path('runs/stage2_scans') / f'{stamp}_stage2_hazp_steps{STEPS}_g{GENERATIONS}_p{POP_SIZE}_ep{TRAIN_EPISODES}_eval{EVAL_EP}.jsonl'\n",
        "log_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "t0 = time.time()\n",
        "\n",
        "with log_path.open('w', encoding='utf-8') as flog:\n",
        "    for cond_id, variant, eta, extra in CONDITIONS:\n",
        "        tag = f'stage2_hazp_{cond_id}_{variant}' + ('' if eta is None else f'_eta{eta:.2f}')\n",
        "        print('\\n=== TRAIN', tag, '===')\n",
        "        out = _run([\n",
        "            'koki2', 'batch-evo-l0',\n",
        "            '--seeds', SEEDS,\n",
        "            '--out-root', OUT_ROOT,\n",
        "            '--tag', tag,\n",
        "            '--generations', str(GENERATIONS),\n",
        "            '--pop-size', str(POP_SIZE),\n",
        "            '--episodes', str(TRAIN_EPISODES),\n",
        "            '--steps', str(STEPS),\n",
        "            '--jit-es',\n",
        "            '--log-every', str(LOG_EVERY),\n",
        "        ] + ENV_BASE + extra)\n",
        "        flog.write(out + '\\n')\n",
        "        flog.flush()\n",
        "\n",
        "        out_dirs = pat_out_dir.findall(out)\n",
        "        if not out_dirs:\n",
        "            raise RuntimeError('no out_dirs parsed for ' + tag)\n",
        "\n",
        "        for eval_seed in EVAL_SEEDS:\n",
        "            # Baselines once per eval seed (same env across conditions).\n",
        "            for policy in ['greedy', 'random']:\n",
        "                out_b = _run([\n",
        "                    'koki2', 'baseline-l0',\n",
        "                    '--seed', str(eval_seed),\n",
        "                    '--policy', policy,\n",
        "                    '--episodes', str(EVAL_EP),\n",
        "                    '--steps', str(STEPS),\n",
        "                    '--bad-source-respawn-delay', '0',\n",
        "                    '--success-bonus', '50',\n",
        "                ] + ENV_BASE)\n",
        "                flog.write(out_b + '\\n')\n",
        "                kv = dict(pat_kv.findall(out_b.strip().splitlines()[-1]))\n",
        "                rows.append({\n",
        "                    'tag': tag,\n",
        "                    'cond': cond_id,\n",
        "                    'variant': variant,\n",
        "                    'plast_eta': eta,\n",
        "                    'kind': f'baseline_{policy}',\n",
        "                    'override_plast_eta': None,\n",
        "                    'eval_seed': eval_seed,\n",
        "                    'run_seed': None,\n",
        "                    'run_dir': None,\n",
        "                    'mean_fitness': float(kv['mean_fitness']),\n",
        "                    'success_rate': float(kv['success_rate']),\n",
        "                    'mean_t_alive': float(kv['mean_t_alive']),\n",
        "                    'mean_energy_gained': float(kv['mean_energy_gained']),\n",
        "                    'mean_bad_arrivals': float(kv['mean_bad_arrivals']),\n",
        "                    'mean_integrity_min': float(kv['mean_integrity_min']),\n",
        "                    'mean_abs_dw_mean': float(kv.get('mean_abs_dw_mean', '0.0')),\n",
        "                    'mean_abs_modulator_mean': float(kv.get('mean_abs_modulator_mean', '0.0')),\n",
        "                    'mean_abs_dw_on_event': float(kv.get('mean_abs_dw_on_event', '0.0')),\n",
        "                    'event_step_frac': float(kv.get('event_step_frac', '0.0')),\n",
        "                })\n",
        "\n",
        "            for d in out_dirs:\n",
        "                out_e = _run([\n",
        "                    'koki2', 'eval-run',\n",
        "                    '--run-dir', d,\n",
        "                    '--episodes', str(EVAL_EP),\n",
        "                    '--seed', str(eval_seed),\n",
        "                    '--baseline-policy', 'none',\n",
        "                ])\n",
        "                flog.write(out_e + '\\n')\n",
        "                best_line = [ln for ln in out_e.splitlines() if ln.startswith('best_genome')][0]\n",
        "                kv = dict(pat_kv.findall(best_line))\n",
        "                m = pat_seed.search(d)\n",
        "                run_seed = int(m.group(1)) if m else None\n",
        "                rows.append({\n",
        "                    'tag': tag,\n",
        "                    'cond': cond_id,\n",
        "                    'variant': variant,\n",
        "                    'plast_eta': eta,\n",
        "                    'kind': 'best_genome',\n",
        "                    'override_plast_eta': None,\n",
        "                    'eval_seed': eval_seed,\n",
        "                    'run_seed': run_seed,\n",
        "                    'run_dir': d,\n",
        "                    'mean_fitness': float(kv['mean_fitness']),\n",
        "                    'success_rate': float(kv['success_rate']),\n",
        "                    'mean_t_alive': float(kv['mean_t_alive']),\n",
        "                    'mean_energy_gained': float(kv['mean_energy_gained']),\n",
        "                    'mean_bad_arrivals': float(kv['mean_bad_arrivals']),\n",
        "                    'mean_integrity_min': float(kv['mean_integrity_min']),\n",
        "                    'mean_abs_dw_mean': float(kv.get('mean_abs_dw_mean', '0.0')),\n",
        "                    'mean_abs_modulator_mean': float(kv.get('mean_abs_modulator_mean', '0.0')),\n",
        "                    'mean_abs_dw_on_event': float(kv.get('mean_abs_dw_on_event', '0.0')),\n",
        "                    'event_step_frac': float(kv.get('event_step_frac', '0.0')),\n",
        "                })\n",
        "\n",
        "                # Causality probe: evaluate the same genome with learning disabled.\n",
        "                if eta is not None and float(eta) > 0.0 and variant != 'noplast':\n",
        "                    out_e0 = _run([\n",
        "                        'koki2', 'eval-run',\n",
        "                        '--run-dir', d,\n",
        "                        '--episodes', str(EVAL_EP),\n",
        "                        '--seed', str(eval_seed),\n",
        "                        '--baseline-policy', 'none',\n",
        "                        '--override-plast-eta', '0.0',\n",
        "                    ])\n",
        "                    flog.write(out_e0 + '\\n')\n",
        "                    best_line0 = [ln for ln in out_e0.splitlines() if ln.startswith('best_genome')][0]\n",
        "                    kv0 = dict(pat_kv.findall(best_line0))\n",
        "                    rows.append({\n",
        "                        'tag': tag,\n",
        "                        'cond': cond_id,\n",
        "                        'variant': variant,\n",
        "                        'plast_eta': eta,\n",
        "                        'kind': 'best_genome_eta0',\n",
        "                        'override_plast_eta': 0.0,\n",
        "                        'eval_seed': eval_seed,\n",
        "                        'run_seed': run_seed,\n",
        "                        'run_dir': d,\n",
        "                        'mean_fitness': float(kv0['mean_fitness']),\n",
        "                        'success_rate': float(kv0['success_rate']),\n",
        "                        'mean_t_alive': float(kv0['mean_t_alive']),\n",
        "                        'mean_energy_gained': float(kv0['mean_energy_gained']),\n",
        "                        'mean_bad_arrivals': float(kv0['mean_bad_arrivals']),\n",
        "                        'mean_integrity_min': float(kv0['mean_integrity_min']),\n",
        "                        'mean_abs_dw_mean': float(kv0.get('mean_abs_dw_mean', '0.0')),\n",
        "                        'mean_abs_modulator_mean': float(kv0.get('mean_abs_modulator_mean', '0.0')),\n",
        "                        'mean_abs_dw_on_event': float(kv0.get('mean_abs_dw_on_event', '0.0')),\n",
        "                        'event_step_frac': float(kv0.get('event_step_frac', '0.0')),\n",
        "                    })\n",
        "\n",
        "jsonl_path.write_text('\\n'.join(json.dumps(r) for r in rows) + '\\n', encoding='utf-8')\n",
        "print('\\nWrote log:', log_path)\n",
        "print('Wrote results:', jsonl_path)\n",
        "print('Total wall time (min):', (time.time() - t0) / 60.0)\n",
        "\n",
        "# Quick summary (mean \u00b1 stdev across ES seeds)\n",
        "best = defaultdict(list)\n",
        "base = {}\n",
        "for r in rows:\n",
        "    k = (r['cond'], r['variant'], r['plast_eta'], r['eval_seed'])\n",
        "    if r['kind'].startswith('baseline_'):\n",
        "        base[(k, r['kind'])] = r\n",
        "    else:\n",
        "        best[(k, r['kind'])].append(r)\n",
        "\n",
        "keys = sorted({k for (k, _kind) in best.keys()})\n",
        "for k in keys:\n",
        "    cond, variant, eta, eval_seed = k\n",
        "    g = base[(k, 'baseline_greedy')]\n",
        "    rnd = base[(k, 'baseline_random')]\n",
        "    rs = best.get((k, 'best_genome'), [])\n",
        "    rs0 = best.get((k, 'best_genome_eta0'), [])\n",
        "    print(f\"\\ncond={cond} variant={variant} eta={eta} eval_seed={eval_seed}\")\n",
        "    for who, vals in [('best', rs), ('best_eta0', rs0), ('greedy', [g]), ('random', [rnd])]:\n",
        "        mf = [v['mean_fitness'] for v in vals]\n",
        "        bb = [v['mean_bad_arrivals'] for v in vals]\n",
        "        im = [v['mean_integrity_min'] for v in vals]\n",
        "        dw = [v['mean_abs_dw_mean'] for v in vals]\n",
        "        dwe = [v.get('mean_abs_dw_on_event', 0.0) for v in vals]\n",
        "        evf = [v.get('event_step_frac', 0.0) for v in vals]\n",
        "        mm = [v.get('mean_abs_modulator_mean', 0.0) for v in vals]\n",
        "        if len(vals) > 1:\n",
        "            print(f\"  {who}: fitness={mean(mf):.4f}\u00b1{stdev(mf):.4f} bad={mean(bb):.4f}\u00b1{stdev(bb):.4f} imin={mean(im):.4f}\u00b1{stdev(im):.4f} dw={mean(dw):.6f}\u00b1{stdev(dw):.6f} dwe={mean(dwe):.6f}\u00b1{stdev(dwe):.6f} evf={mean(evf):.4f}\u00b1{stdev(evf):.4f} mod={mean(mm):.6f}\u00b1{stdev(mm):.6f}\")\n",
        "        else:\n",
        "            print(f\"  {who}: fitness={mf[0]:.4f} bad={bb[0]:.4f} imin={im[0]:.4f} dw={dw[0]:.6f} dwe={dwe[0]:.6f} evf={evf[0]:.4f} mod={mm[0]:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
